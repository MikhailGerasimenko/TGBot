version: '3.8'

services:
  model-service:
    build:
      context: ..
      dockerfile: docker/Dockerfile.model
    container_name: corporate-bot-model-gpu
    ports:
      - "8000:8000"
    volumes:
      - ../models:/app/models
      - ../data:/app/data
      - ../logs:/app/logs
    environment:
      - GGUF_MODEL_PATH=/app/models/model-gigachat_20b_bf16.gguf
      - LLAMA_CTX=8192
      - LLAMA_THREADS=16
      - LLAMA_BATCH=1024
      - LLAMA_GPU_LAYERS=80
      - MAX_NEW_TOKENS=512
      - EMBEDDING_MODEL_NAME=paraphrase-multilingual-MiniLM-L12-v2
      - CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-12-v2
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  telegram-bot:
    build:
      context: ..
      dockerfile: docker/Dockerfile.bot
    container_name: corporate-bot-telegram-gpu
    depends_on:
      model-service:
        condition: service_healthy
    volumes:
      - ../data:/app/data
      - ../documents:/app/documents
      - ../logs:/app/logs
    environment:
      - MODEL_SERVICE_URL=http://model-service:8000
      - API_TOKEN=${API_TOKEN}
      - ADMIN_CHAT_ID=${ADMIN_CHAT_ID}
      - DATABASE_PATH=/app/data/employees.db
      - DOCS_DIR=/app/documents
      - LOGS_DIR=/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://model-service:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    container_name: corporate-bot-nginx-gpu
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ../logs:/var/log/nginx
    depends_on:
      - model-service
    restart: unless-stopped

  redis:
    image: redis:alpine
    container_name: corporate-bot-redis-gpu
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  monitoring:
    image: grafana/grafana:latest
    container_name: corporate-bot-monitoring
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    restart: unless-stopped

volumes:
  redis_data:
  grafana_data: 