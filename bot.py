import logging
from aiogram import Bot, types, Dispatcher
from aiogram.filters import Command
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove, InlineKeyboardMarkup, InlineKeyboardButton
import os
import asyncio
from typing import List, Dict, Optional, Set
from datetime import datetime, timedelta
from database import (verify_employee, log_registration_attempt, get_registration_attempts, get_all_employees,
                     log_qa_session, save_feedback, log_unanswered_question, get_analytics_stats, get_popular_questions)
from llm_client import LLMClient
import numpy as np
from docx import Document
import re
from collections import defaultdict
from config import API_TOKEN, ADMIN_CHAT_ID, DOCS_DIR as DOCUMENTS_DIR, LOGS_DIR, ONEC_EXPORT_PATH
from onec_sync import load_employees_from_file
import time

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è LLM (—á–µ—Ä–µ–∑ —Å–µ—Ä–≤–∏—Å)
MAX_LENGTH = 2048
MAX_NEW_TOKENS = 512

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤
llm_client = LLMClient()

auth_logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(LOGS_DIR, 'bot.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=API_TOKEN)

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä—ã
main_kb = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text='–ü–æ–º–æ—â—å'), KeyboardButton(text='–°–ø—Ä–æ—Å–∏—Ç—å')],
    ],
    resize_keyboard=True
)
retry_kb = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text='–ø–æ–≤—Ç–æ—Ä')], [KeyboardButton(text='–û—Ç–º–µ–Ω–∞')]],
    resize_keyboard=True
)

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É
async def send_admin_notification(text: str) -> bool:
    try:
        await bot.send_message(ADMIN_CHAT_ID, text, parse_mode='HTML')
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É: {e}")
        return False

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–≤–æ–¥–∞ –∏ –¥–∞–Ω–Ω—ã—Ö
DASHES = "\u2010\u2011\u2012\u2013\u2014\u2212\uFE58\uFE63\uFF0D"
DASH_TRANS = str.maketrans({c: '-' for c in DASHES})

def normalize_spaces(text: str) -> str:
    return re.sub(r"\s+", " ", (text or "").strip())

def normalize_name(text: str) -> str:
    return normalize_spaces(text).lower()

def normalize_employee_id(text: str) -> str:
    t = (text or "").translate(DASH_TRANS)
    t = t.replace(' ', '')  # —É–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏
    return t.upper()

# ========== –î–ê–ù–ù–´–ï –ò –°–û–°–¢–û–Ø–ù–ò–Ø (–±–µ–∑ Redis) ==========

# –ö—ç—à —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ –ø–∞–º—è—Ç–∏ (employee_id -> dict)
EMPLOYEES_CACHE: Dict[str, dict] = {}
# –ò–Ω–¥–µ–∫—Å –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É ID
EMPLOYEES_BY_NORM_ID: Dict[str, dict] = {}

# –ü–æ–ø—ã—Ç–∫–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
REGISTRATION_ATTEMPTS: Dict[int, Dict[str, any]] = {}
MAX_ATTEMPTS = 3
RETRY_COMMANDS = ['retry', '–ø–æ–≤—Ç–æ—Ä', '–∑–∞–Ω–æ–≤–æ']
USER_STATES: Dict[int, Dict[str, any]] = {}
AUTHORIZED_USERS: Set[int] = set()
AUTHORIZED_INFO: Dict[int, Dict[str, str]] = {}

async def set_user_state(user_id: int, key: str, value: str):
    state = USER_STATES.get(user_id, {})
    state[key] = value
    USER_STATES[user_id] = state

async def get_user_state(user_id: int, key: str) -> Optional[str]:
    return USER_STATES.get(user_id, {}).get(key)

async def clear_user_state(user_id: int):
    if user_id in USER_STATES:
        del USER_STATES[user_id]

async def can_try_registration(user_id: int) -> bool:
    now_key = datetime.now().strftime('%Y%m%d')
    data = REGISTRATION_ATTEMPTS.get(user_id)
    if not data or data.get('date') != now_key:
        return True
    return data.get('count', 0) < MAX_ATTEMPTS

async def inc_registration_attempt(user_id: int):
    now_key = datetime.now().strftime('%Y%m%d')
    data = REGISTRATION_ATTEMPTS.get(user_id)
    if not data or data.get('date') != now_key:
        REGISTRATION_ATTEMPTS[user_id] = {'date': now_key, 'count': 1}
    else:
        data['count'] = data.get('count', 0) + 1
        REGISTRATION_ATTEMPTS[user_id] = data

async def get_next_attempt_time(user_id: int) -> str:
    data = REGISTRATION_ATTEMPTS.get(user_id)
    if not data:
        return "—Å–µ–π—á–∞—Å"
    next_day = datetime.strptime(data['date'], '%Y%m%d') + timedelta(days=1)
    return next_day.strftime('%d.%m.%Y –≤ %H:%M')

async def load_employees_from_file_to_cache() -> int:
    if not ONEC_EXPORT_PATH:
        return 0
    try:
        rows = await load_employees_from_file(ONEC_EXPORT_PATH)
        EMPLOYEES_CACHE.clear()
        EMPLOYEES_BY_NORM_ID.clear()
        for emp in rows:
            emp_id = emp['employee_id']
            EMPLOYEES_CACHE[emp_id] = emp
            norm = normalize_employee_id(emp_id)
            emp['norm_id'] = norm
            emp['norm_name'] = normalize_name(emp.get('full_name', ''))
            EMPLOYEES_BY_NORM_ID[norm] = emp
        logger.info(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ —Ñ–∞–π–ª–∞: {len(rows)} –∑–∞–ø–∏—Å–µ–π")
        return len(rows)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞: {e}")
        return 0

IC_CACHE = {
    "last_sync": None,
    "sync_in_progress": False
}

async def sync_with_1c():
    if IC_CACHE["sync_in_progress"]:
        return False
    try:
        IC_CACHE["sync_in_progress"] = True
        success = False
        if ONEC_EXPORT_PATH:
            cnt = await load_employees_from_file_to_cache()
            success = cnt > 0
        else:
            employees = await get_all_employees()
            EMPLOYEES_CACHE.clear()
            EMPLOYEES_BY_NORM_ID.clear()
            for emp in employees:
                EMPLOYEES_CACHE[emp["employee_id"]] = emp
                norm = normalize_employee_id(emp["employee_id"])
                emp['norm_id'] = norm
                emp['norm_name'] = normalize_name(emp.get('full_name', ''))
                EMPLOYEES_BY_NORM_ID[norm] = emp
            success = len(EMPLOYEES_CACHE) > 0
        if success:
            IC_CACHE["last_sync"] = datetime.now()
            logger.info("Successfully synced employees (memory cache)")
            return True
        return False
    except Exception as e:
        logger.error(f"Error syncing employees: {e}")
        return False
    finally:
        IC_CACHE["sync_in_progress"] = False

async def periodic_sync():
    while True:
        try:
            if (not IC_CACHE["last_sync"] or 
                datetime.now() - IC_CACHE["last_sync"] > timedelta(hours=1)):
                logger.info("–ó–∞–ø—É—Å–∫ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏")
                success = await sync_with_1c()
                if success:
                    await send_admin_notification(
                        f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\n"
                        f"üïí –í—Ä–µ–º—è: {IC_CACHE['last_sync'].strftime('%Y-%m-%d %H:%M:%S')}"
                    )
                    await asyncio.sleep(3600)
                else:
                    await asyncio.sleep(300)
            else:
                await asyncio.sleep(60)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ periodic_sync: {e}")
            await asyncio.sleep(300)

async def verify_user_in_1c(full_name: str, employee_id: str) -> Optional[dict]:
    try:
        if not IC_CACHE["last_sync"] or datetime.now() - IC_CACHE["last_sync"] > timedelta(hours=1):
            await sync_with_1c()
        norm_id = normalize_employee_id(employee_id)
        norm_name = normalize_name(full_name)
        emp = EMPLOYEES_BY_NORM_ID.get(norm_id)
        if emp and emp.get('norm_name') == norm_name:
            return {
                "verified": True,
                "department": emp.get("department", ""),
                "position": emp.get("position", ""),
                "employee_id": emp.get("employee_id", employee_id),
                "from_cache": True
            }
        result = await verify_employee(full_name, employee_id)
        logger.info(f"Employee verification result for {full_name} (ID: {employee_id}): {result}")
        return result
    except Exception as e:
        logger.error(f"Employee verification error: {e}")
        return None

# ========== –§–£–ù–ö–¶–ò–ò –î–õ–Ø –†–ê–ë–û–¢–´ –° –î–û–ö–£–ú–ï–ù–¢–ê–ú–ò ==========

def extract_text_from_docx(file_path: str) -> str:
    try:
        doc = Document(file_path)
        full_text = []
        for para in doc.paragraphs:
            text = re.sub(r'\s+', ' ', para.text.strip())
            if text:
                full_text.append(text)
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    text = re.sub(r'\s+', ' ', cell.text.strip())
                    if text:
                        full_text.append(text)
        return '\n'.join(full_text)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        return ""

def split_text_into_chunks(text: str, chunk_size: int = 500) -> List[str]:
    sentences = text.split('.')
    chunks = []
    current_chunk = []
    current_length = 0
    for sentence in sentences:
        sentence = sentence.strip() + '.'
        sentence_length = len(sentence.split())
        if current_length + sentence_length > chunk_size:
            if current_chunk:
                chunks.append(' '.join(current_chunk))
            current_chunk = [sentence]
            current_length = sentence_length
        else:
            current_chunk.append(sentence)
            current_length += sentence_length
    if current_chunk:
        chunks.append(' '.join(current_chunk))
    return chunks

def extract_metadata_from_text(text: str) -> Dict[str, str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    metadata = {}
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
    text_lower = text.lower()
    if any(keyword in text_lower for keyword in ['—Ä–µ–≥–ª–∞–º–µ–Ω—Ç', '–ø—Ä–æ—Ü–µ–¥—É—Ä–∞', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è']):
        metadata['doc_type'] = 'regulation'
    elif any(keyword in text_lower for keyword in ['faq', '—á–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ', '–≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã']):
        metadata['doc_type'] = 'faq'
    elif any(keyword in text_lower for keyword in ['—Å–ø—Ä–∞–≤–∫–∞', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ', '–ø–æ–º–æ—â—å']):
        metadata['doc_type'] = 'guide'
    else:
        metadata['doc_type'] = 'document'
    
    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ—Ç–¥–µ–ª–æ–≤
    departments = ['hr', '–∏—Ç', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è', '–ø—Ä–æ–¥–∞–∂–∏', '–º–∞—Ä–∫–µ—Ç–∏–Ω–≥', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å']
    for dept in departments:
        if dept in text_lower:
            metadata['department'] = dept
            break
    
    # –ò—â–µ–º –¥–∞—Ç—ã (–ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω)
    date_patterns = [
        r'\d{1,2}\.\d{1,2}\.\d{4}',  # 01.01.2024
        r'\d{4}-\d{1,2}-\d{1,2}',   # 2024-01-01
        r'\d{1,2}/\d{1,2}/\d{4}'    # 01/01/2024
    ]
    
    for pattern in date_patterns:
        matches = re.findall(pattern, text)
        if matches:
            metadata['dates'] = matches[:3]  # –ú–∞–∫—Å–∏–º—É–º 3 –¥–∞—Ç—ã
            break
    
    return metadata

def smart_chunk_documents(text: str, filename: str = "") -> List[Dict]:
    """–£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
    chunks = []
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    doc_metadata = extract_metadata_from_text(text)
    doc_metadata['filename'] = filename
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    doc_type = doc_metadata.get('doc_type', 'document')
    
    if doc_type == 'regulation':
        # –î–ª—è —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–æ–≤ - —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—É–Ω–∫—Ç–∞–º
        chunk_pattern = r'(?:^|\n)\s*\d+(?:\.\d+)*\.?\s+[–ê-–Ø–Å].*?(?=(?:^|\n)\s*\d+(?:\.\d+)*\.?\s+[–ê-–Ø–Å]|$)'
        min_chunk_size = 100
        max_chunk_size = 800
    elif doc_type == 'faq':
        # –î–ª—è FAQ - —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º
        chunk_pattern = r'(?:^|\n)\s*(?:–í:|–í–æ–ø—Ä–æ—Å:|Q:).*?(?=(?:^|\n)\s*(?:–í:|–í–æ–ø—Ä–æ—Å:|Q:)|$)'
        min_chunk_size = 50
        max_chunk_size = 600
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –∞–±–∑–∞—Ü–∞–º –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
        chunk_pattern = r'[^.!?]*[.!?]+(?:\s+[^.!?]*[.!?]+)*'
        min_chunk_size = 150
        max_chunk_size = 500
    
    # –ü—ã—Ç–∞–µ–º—Å—è —É–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
    try:
        matches = re.finditer(chunk_pattern, text, re.DOTALL | re.MULTILINE)
        potential_chunks = [match.group().strip() for match in matches]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏
        current_chunk = ""
        chunk_counter = 0
        
        for chunk_text in potential_chunks:
            if not chunk_text:
                continue
                
            # –ï—Å–ª–∏ —á–∞–Ω–∫ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º
            if len(chunk_text) < min_chunk_size and current_chunk:
                current_chunk += " " + chunk_text
            else:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —á–∞–Ω–∫ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if current_chunk and len(current_chunk) >= min_chunk_size:
                    chunks.append({
                        'text': current_chunk.strip(),
                        'chunk_id': chunk_counter,
                        'metadata': {**doc_metadata, 'chunk_size': len(current_chunk)}
                    })
                    chunk_counter += 1
                
                current_chunk = chunk_text
            
            # –ï—Å–ª–∏ —á–∞–Ω–∫ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–∞–ª—å—à–µ
            if len(current_chunk) > max_chunk_size:
                # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                sentences = current_chunk.split('. ')
                temp_chunk = ""
                
                for sentence in sentences:
                    if len(temp_chunk + sentence) > max_chunk_size and temp_chunk:
                        chunks.append({
                            'text': temp_chunk.strip() + '.',
                            'chunk_id': chunk_counter,
                            'metadata': {**doc_metadata, 'chunk_size': len(temp_chunk)}
                        })
                        chunk_counter += 1
                        temp_chunk = sentence
                    else:
                        temp_chunk += sentence + ". " if temp_chunk else sentence
                
                current_chunk = temp_chunk
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
        if current_chunk and len(current_chunk) >= min_chunk_size:
            chunks.append({
                'text': current_chunk.strip(),
                'chunk_id': chunk_counter,
                'metadata': {**doc_metadata, 'chunk_size': len(current_chunk)}
            })
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–º–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è: {e}, fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É")
        # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É —Ä–∞–∑–±–∏–µ–Ω–∏—é
        simple_chunks = split_text_into_chunks(text, max_chunk_size)
        for i, chunk_text in enumerate(simple_chunks):
            chunks.append({
                'text': chunk_text,
                'chunk_id': i,
                'metadata': {**doc_metadata, 'chunk_size': len(chunk_text), 'method': 'simple'}
            })
    
    logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤ (—Ç–∏–ø: {doc_type})")
    return chunks

async def index_document(file_path: str) -> bool:
    global document_embeddings, document_chunks
    try:
        text = extract_text_from_docx(file_path)
        if not text:
            return False
        chunks = split_text_into_chunks(text)
        embeddings = await llm_client.create_embeddings(chunks)
        if embeddings is None:
            return False
        embeddings = np.array(embeddings)
        document_chunks.extend(chunks)
        if document_embeddings is None:
            document_embeddings = embeddings
        else:
            document_embeddings = np.vstack([document_embeddings, embeddings])
        logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç {file_path} —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω")
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        return False

async def awaitable_create_query_embedding(query: str):
    try:
        return await llm_client.create_embeddings([query])
    except Exception:
        return None

def find_relevant_chunks(query: str, top_k: int = 3) -> List[str]:
    if not document_embeddings is None and len(document_chunks) > 0:
        try:
            loop = asyncio.get_event_loop()
            query_embedding_list = loop.run_until_complete(awaitable_create_query_embedding(query))
            if query_embedding_list is None:
                return []
            query_embedding = np.array(query_embedding_list[0])
            similarities = np.dot(document_embeddings, query_embedding)
            top_indices = np.argsort(similarities)[-top_k:][::-1]
            return [document_chunks[i] for i in top_indices]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {e}")
    return []

async def generate_response(query: str, context: str = "") -> str:
    try:
        response = await llm_client.generate(query=query, context=context, max_tokens=MAX_NEW_TOKENS)
        if response is None:
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."
        return response
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è RAG
document_embeddings = None
document_chunks = []

# –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ—Å—Å–∏–π Q&A –∏ —Å–≤—è–∑—ã–≤–∞–Ω–∏—è —Å feedback
QA_SESSIONS: Dict[int, int] = {}  # message_id -> qa_session_id

# A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
USE_SEARCH_V2 = os.getenv('USE_SEARCH_V2', 'false').lower() == 'true'
SEARCH_V2_PERCENTAGE = int(os.getenv('SEARCH_V2_PERCENTAGE', '30'))  # % –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–∞
ALLOWED_EXTENSIONS = {'.docx'}

def _sanitize_filename(name: str) -> str:
    name = re.sub(r"[^\w\-\.]+", "_", name)
    return name.strip("._") or f"doc_{int(datetime.now().timestamp())}.docx"

async def expand_query(original_query: str) -> List[str]:
    """–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫"""
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∫–∏
        rephrase_prompt = f"""–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å 2 —Å–ø–æ—Å–æ–±–∞–º–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:

–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å: "{original_query}"

–í–∞—Ä–∏–∞–Ω—Ç—ã:
1."""
        
        response = await llm_client.generate(
            query=rephrase_prompt,
            max_tokens=150,
            temperature=0.3
        )
        
        if response:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞
            variants = []
            for line in response.split('\n'):
                line = line.strip()
                if line and any(line.startswith(prefix) for prefix in ['1.', '2.', '‚Ä¢', '-']):
                    # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é
                    clean_line = re.sub(r'^[12]\.\s*|^[‚Ä¢-]\s*', '', line).strip()
                    if clean_line and len(clean_line) > 10:
                        variants.append(clean_line)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª + –º–∞–∫—Å–∏–º—É–º 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞
            result = [original_query] + variants[:2]
            logger.info(f"Query expansion: {len(result)} variants generated")
            return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
    
    # Fallback - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    return [original_query]

def should_use_search_v2(user_id: int) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –ø–æ–∏—Å–∫–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if USE_SEARCH_V2:
        return True
    
    # A/B —Ç–µ—Å—Ç: –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏
    return (user_id % 100) < SEARCH_V2_PERCENTAGE

async def search_documents(query: str, user_id: int = 0, use_expansion: bool = True) -> tuple:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å –≤—ã–±–æ—Ä–æ–º –≤–µ—Ä—Å–∏–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º –∑–∞–ø—Ä–æ—Å–æ–≤"""
    try:
        search_version = "v2" if should_use_search_v2(user_id) else "v1"
        endpoint = "/search_v2" if search_version == "v2" else "/search"
        
        # Query expansion –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        queries_to_search = [query]
        if use_expansion and len(query) > 20:  # –†–∞—Å—à–∏—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –¥–ª–∏–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            queries_to_search = await expand_query(query)
        
        all_hits = []
        confidence_scores = []
        
        import aiohttp
        async with aiohttp.ClientSession() as session:
            for search_query in queries_to_search:
                async with session.post(f"{llm_client.base_url}{endpoint}", 
                                      json={"query": search_query, "top_k": 3}) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        hits = data.get('hits', [])
                        if hits:
                            all_hits.extend(hits)
                            confidence_scores.extend([h['score'] for h in hits])
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
        seen_texts = set()
        unique_hits = []
        for hit in all_hits:
            text_hash = hash(hit['text'][:100])  # –•–µ—à –ø–µ—Ä–≤—ã—Ö 100 —Å–∏–º–≤–æ–ª–æ–≤
            if text_hash not in seen_texts:
                seen_texts.add(text_hash)
                unique_hits.append(hit)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É –∏ –±–µ—Ä—ë–º —Ç–æ–ø-3
        unique_hits.sort(key=lambda x: x['score'], reverse=True)
        final_hits = unique_hits[:3]
        
        if final_hits:
            top_context = "\n\n".join(h['text'] for h in final_hits)
            sources_block = f"\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏ ({search_version}):\n" + "\n".join([f"‚Äî {round(h['score'],3)}" for h in final_hits])
            top_score = final_hits[0]['score']
            
            return top_context, sources_block, top_score, True, search_version
        else:
            return "", "", 0.0, False, search_version
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ search_documents: {e}")
        return "", "", 0.0, False, "error"

async def rebuild_service_index_from_docs() -> int:
    try:
        documents: List[str] = []
        for fname in os.listdir(DOCUMENTS_DIR):
            if not any(fname.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):
                continue
            fpath = os.path.join(DOCUMENTS_DIR, fname)
            text = extract_text_from_docx(fpath)
            if not text:
                continue
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            smart_chunks = smart_chunk_documents(text, fname)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (–ø–æ–∫–∞ —á—Ç–æ)
            chunk_texts = [chunk['text'] for chunk in smart_chunks if chunk['text'].strip()]
            documents.extend(chunk_texts)
            
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω {fname}: {len(chunk_texts)} —á–∞–Ω–∫–æ–≤")
            
        if not documents:
            logger.info("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            return 0
            
        import aiohttp
        async with aiohttp.ClientSession() as session:
            async with session.post(f"{llm_client.base_url}/index", json={"documents": documents}) as resp:
                if resp.status != 200:
                    err = await resp.text()
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ /index: {err}")
                    return 0
                data = await resp.json()
                logger.info(f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—á–∞–Ω–∫–æ–≤): {data}")
                
        return len(documents)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ —Å–µ—Ä–≤–∏—Å–∞: {e}")
        return 0

def create_feedback_keyboard(qa_session_id: int) -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞—ë—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –ª–∞–π–∫/–¥–∏–∑–ª–∞–π–∫ –¥–ª—è —Ñ–∏–¥–±–µ–∫–∞."""
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="üëç", callback_data=f"feedback_like_{qa_session_id}"),
            InlineKeyboardButton(text="üëé", callback_data=f"feedback_dislike_{qa_session_id}")
        ]
    ])
    return keyboard

# ========== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ==========

def setup_handlers(dp: Dispatcher):
    @dp.message(Command('start'))
    async def start_handler(message: types.Message):
        user_id = message.from_user.id
        if not API_TOKEN:
            await message.answer('‚ùå –ù–µ –∑–∞–¥–∞–Ω API_TOKEN. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ .env')
            return
        if user_id in AUTHORIZED_USERS:
            await message.answer('–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –í—ã –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã.', reply_markup=main_kb)
            return
        if await can_try_registration(user_id):
            await set_user_state(user_id, 'step', 'name')
            await message.answer(
                '–î–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –≤–≤–µ–¥–∏—Ç–µ –≤–∞—à–µ –§–ò–û\n'
                '(–∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ 1–°, –Ω–∞–ø—Ä–∏–º–µ—Ä: –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á)'
            )
        else:
            next_attempt = await get_next_attempt_time(user_id)
            await message.answer(
                f"‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏.\n"
                f"–°–ª–µ–¥—É—é—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ {next_attempt}.\n\n"
                f"–ï—Å–ª–∏ –≤–∞–º –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.",
                reply_markup=ReplyKeyboardRemove()
            )

    @dp.message(Command('cancel'))
    async def cancel_handler(message: types.Message):
        user_id = message.from_user.id
        await clear_user_state(user_id)
        await message.answer('–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏.', reply_markup=ReplyKeyboardRemove())

    # –†—É—Å—Å–∫–∞—è –∫–Ω–æ–ø–∫–∞ ¬´–û—Ç–º–µ–Ω–∞¬ª
    @dp.message(lambda m: m.text and m.text.strip().lower() == '–æ—Ç–º–µ–Ω–∞')
    async def cancel_button(message: types.Message):
        await cancel_handler(message)

    @dp.message(Command('status'))
    async def status_handler(message: types.Message):
        user_id = message.from_user.id
        if user_id not in AUTHORIZED_USERS:
            await message.answer('‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start.')
            return
        info = AUTHORIZED_INFO.get(user_id, {})
        await message.answer(
            f"üë§ –§–ò–û: {info.get('name','-')}\n"
            f"üî¢ –¢–∞–±–µ–ª—å–Ω—ã–π: {info.get('employee_id','-')}\n"
            f"üïí –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è: {info.get('verified_at','-')}",
            reply_markup=main_kb
        )

    # ====== –ê–¥–º–∏–Ω: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (SOP .docx) ======
    @dp.message(Command('train'))
    async def train_handler(message: types.Message):
        if message.from_user.id != ADMIN_CHAT_ID:
            await message.answer('‚ùå –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.')
            return
        await set_user_state(message.from_user.id, 'awaiting_doc_upload', '1')
        await message.answer(
            '–ü—Ä–∏—à–ª–∏—Ç–µ —Ñ–∞–π–ª .docx (SOP/—Ä–µ–≥–ª–∞–º–µ–Ω—Ç). –Ø —Å–æ—Ö—Ä–∞–Ω—é –µ–≥–æ –∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä—É—é –ø–æ–∏—Å–∫.',
            reply_markup=ReplyKeyboardRemove()
        )

    @dp.message(lambda m: m.document is not None)
    async def handle_document_upload(message: types.Message):
        try:
            user_id = message.from_user.id
            doc = message.document
            file_name = (doc.file_name or 'document.docx')
            ext = os.path.splitext(file_name)[1].lower()
            awaiting = await get_user_state(user_id, 'awaiting_doc_upload')
            # –†–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω—É –∏ —Ç–æ–ª—å–∫–æ .docx
            if user_id != ADMIN_CHAT_ID:
                return
            if ext not in ALLOWED_EXTENSIONS:
                if awaiting:
                    await message.answer('‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .docx. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.')
                return
            # –ü—É—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            safe_name = _sanitize_filename(file_name)
            save_path = os.path.join(DOCUMENTS_DIR, safe_name)
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            await bot.download(doc, destination=save_path)
            await set_user_state(user_id, 'awaiting_doc_upload', '0')
            # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            chunks_count = await rebuild_service_index_from_docs()
            await message.answer(
                f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {safe_name}\nüìö –ò–Ω–¥–µ–∫—Å –æ–±–Ω–æ–≤–ª—ë–Ω, —á–∞–Ω–∫–æ–≤: {chunks_count}",
                reply_markup=main_kb
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            await message.answer('‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.', reply_markup=main_kb)

    @dp.message(lambda message: message.text and message.text.lower() in RETRY_COMMANDS)
    async def retry_registration(message: types.Message):
        user_id = message.from_user.id
        if user_id in AUTHORIZED_USERS:
            await message.answer('–í—ã —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã.', reply_markup=main_kb)
            return
        if await can_try_registration(user_id):
            await clear_user_state(user_id)
            await set_user_state(user_id, 'step', 'name')
            await message.answer(
                "üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –∑–∞–Ω–æ–≤–æ!\n\n"
                "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à–µ –§–ò–û\n"
                "(–∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ 1–°, –Ω–∞–ø—Ä–∏–º–µ—Ä: –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á)",
                reply_markup=ReplyKeyboardRemove()
            )
        else:
            next_attempt = await get_next_attempt_time(user_id)
            await message.answer(
                f"‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏.\n"
                f"–°–ª–µ–¥—É—é—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ {next_attempt}.\n\n"
                f"–ï—Å–ª–∏ –≤–∞–º –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.",
                reply_markup=ReplyKeyboardRemove()
            )

    @dp.message(lambda message: True)
    async def registration_handler(message: types.Message):
        user_id = message.from_user.id
        step = await get_user_state(user_id, 'step')
        if not step:
            return
        if step == 'name':
            name_parts = message.text.strip().split()
            if len(name_parts) != 3:
                await message.answer(
                    '‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –§–ò–û –ø–æ–ª–Ω–æ—Å—Ç—å—é\n'
                    '–§–æ—Ä–º–∞—Ç: –§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ\n'
                    '–ü—Ä–∏–º–µ—Ä: –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á\n\n'
                    '–î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ –Ω–∞–ø–∏—à–∏—Ç–µ "–ø–æ–≤—Ç–æ—Ä"'
                )
                return
            await set_user_state(user_id, 'name', message.text.strip())
            await set_user_state(user_id, 'step', 'employee_id')
            await message.answer(
                '–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–∞–±–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä\n'
                '(–∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ 1–°, –Ω–∞–ø—Ä–∏–º–µ—Ä: E001)'
            )
        elif step == 'employee_id':
            employee_id = message.text.strip()
            name = await get_user_state(user_id, 'name')
            await set_user_state(user_id, 'employee_id', employee_id)
            verification_result = await verify_user_in_1c(name, employee_id)
            if verification_result and verification_result.get('verified'):
                await clear_user_state(user_id)
                AUTHORIZED_USERS.add(user_id)
                AUTHORIZED_INFO[user_id] = {
                    'name': name,
                    'employee_id': employee_id,
                    'department': verification_result.get('department',''),
                    'position': verification_result.get('position',''),
                    'verified_at': datetime.now().strftime('%Y-%m-%d %H:%M')
                }
                await log_registration_attempt(user_id, name, employee_id, True)
                await message.answer(
                    f"‚úÖ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞!\n\n"
                    f"üìã –í–∞—à–∏ –¥–∞–Ω–Ω—ã–µ:\n"
                    f"üë§ –§–ò–û: {name}\n"
                    f"üî¢ –¢–∞–±–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä: {employee_id}\n"
                    f"üìù –î–æ–ª–∂–Ω–æ—Å—Ç—å: {verification_result.get('position', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}\n"
                    f"üè¢ –û—Ç–¥–µ–ª: {verification_result.get('department', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n\n"
                    f"–¢–µ–ø–µ—Ä—å –≤–∞–º –¥–æ—Å—Ç—É–ø–Ω—ã –∫–æ–º–∞–Ω–¥—ã /ask –∏ /help.",
                    reply_markup=main_kb
                )
            else:
                await inc_registration_attempt(user_id)
                await log_registration_attempt(user_id, name or '', employee_id, False)
                attempts = REGISTRATION_ATTEMPTS.get(user_id, {}).get('count', 0)
                attempts_left = MAX_ATTEMPTS - attempts
                error_msg = [
                    "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
                    "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:",
                    "1. –ù–µ–≤–µ—Ä–Ω–æ —É–∫–∞–∑–∞–Ω–æ –§–ò–û",
                    "2. –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∞–±–µ–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä",
                    "3. –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –±–∞–∑–æ–π\n"
                ]
                if attempts_left > 0:
                    error_msg.append(f"–£ –≤–∞—Å –æ—Å—Ç–∞–ª–æ—Å—å –ø–æ–ø—ã—Ç–æ–∫: {attempts_left}")
                    error_msg.append("–î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–ø–æ–≤—Ç–æ—Ä' –∏–ª–∏ /cancel")
                else:
                    next_attempt = await get_next_attempt_time(user_id)
                    error_msg.append(f"–°–ª–µ–¥—É—é—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ {next_attempt}")
                await message.answer('\n'.join(error_msg), reply_markup=retry_kb)
                await clear_user_state(user_id)

    # –ö–æ–º–∞–Ω–¥–∞ /ask
    @dp.message(Command('ask'))
    async def ask_handler(message: types.Message):
        user_id = message.from_user.id
        if user_id not in AUTHORIZED_USERS:
            await message.answer("‚ùå –í—ã –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏.")
            return
        awaiting = await get_user_state(user_id, 'awaiting_question')
        if not awaiting:
            await set_user_state(user_id, 'awaiting_question', '1')
        await message.answer(
            "–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å. –Ø –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É—è –¥–æ—Å—Ç—É–ø–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.",
            reply_markup=ReplyKeyboardRemove()
        )

    # –ö–Ω–æ–ø–∫–∞ ¬´–°–ø—Ä–æ—Å–∏—Ç—å¬ª (—Ä—É—Å—Å–∫–∞—è)
    @dp.message(lambda m: m.text and m.text.strip().lower() == '—Å–ø—Ä–æ—Å–∏—Ç—å')
    async def ask_button(message: types.Message):
        await ask_handler(message)

    @dp.message(lambda message: True)
    async def process_question(message: types.Message):
        user_id = message.from_user.id
        if user_id not in AUTHORIZED_USERS:
            return
        awaiting = await get_user_state(user_id, 'awaiting_question')
        if not awaiting:
            return
        await set_user_state(user_id, 'awaiting_question', '0')
        
        start_time = time.time()
        processing_msg = await message.answer("ü§î –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –≤–æ–ø—Ä–æ—Å...")
        
        try:
            import aiohttp
            top_context = ""
            sources_block = ""
            conf_threshold = 0.12
            confidence_score = 0.0
            context_found = False
            
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–∏—Å–∫–∞
                top_context, sources_block, confidence_score, context_found, search_version = await search_documents(message.text, user_id)
                
                if not context_found:
                    # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫ –Ω–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å
                    user_info = AUTHORIZED_INFO.get(user_id, {})
                    await log_unanswered_question(
                        user_id, 
                        message.text, 
                        f"Department: {user_info.get('department', '')}, Position: {user_info.get('position', '')}"
                    )
                    await processing_msg.edit_text(
                        "–Ø –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ. –£—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –¥–µ—Ç–∞–ª–µ–π (–¥–∞—Ç–∞, –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ, –¥–æ–∫—É–º–µ–Ω—Ç)."
                    )
                    return
                
                if confidence_score < conf_threshold:
                    # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫ –Ω–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å
                    user_info = AUTHORIZED_INFO.get(user_id, {})
                    await log_unanswered_question(
                        user_id, 
                        message.text, 
                        f"Department: {user_info.get('department', '')}, Position: {user_info.get('position', '')}, Search: {search_version}"
                    )
                    await processing_msg.edit_text(
                        f"–Ø –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ (–ø–æ–∏—Å–∫: {search_version}). –£—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –¥–µ—Ç–∞–ª–µ–π (–¥–∞—Ç–∞, –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ, –¥–æ–∫—É–º–µ–Ω—Ç)."
                    )
                    return
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")

            context = top_context
            response = await generate_response(message.text, context)
            
            # –ó–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
            response_time_ms = int((time.time() - start_time) * 1000)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é Q&A —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–µ—Ä—Å–∏–∏ –ø–æ–∏—Å–∫–∞
            user_info = AUTHORIZED_INFO.get(user_id, {})
            qa_session_id = await log_qa_session(
                telegram_id=user_id,
                user_name=user_info.get('name', message.from_user.full_name or ''),
                employee_id=user_info.get('employee_id', ''),
                question=message.text,
                answer=f"[{search_version}] {response}",  # –ü–æ–º–µ—á–∞–µ–º –≤–µ—Ä—Å–∏—é –ø–æ–∏—Å–∫–∞
                response_time_ms=response_time_ms,
                confidence_score=confidence_score,
                context_found=context_found
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å –∫–Ω–æ–ø–∫–∞–º–∏ —Ñ–∏–¥–±–µ–∫–∞
            feedback_kb = create_feedback_keyboard(qa_session_id)
            sent_msg = await processing_msg.edit_text(
                f"–í–æ–ø—Ä–æ—Å: {message.text}\n\n"
                f"–û—Ç–≤–µ—Ç: {response}{sources_block}",
                reply_markup=feedback_kb
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤—è–∑—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Å–µ—Å—Å–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∏–¥–±–µ–∫–∞
            if qa_session_id:
                QA_SESSIONS[sent_msg.message_id] = qa_session_id
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}")
            await processing_msg.edit_text(
                "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                reply_markup=main_kb
            )

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ callback –¥–ª—è –∫–Ω–æ–ø–æ–∫ —Ñ–∏–¥–±–µ–∫–∞
    @dp.callback_query(lambda c: c.data and c.data.startswith('feedback_'))
    async def process_feedback(callback_query: types.CallbackQuery):
        try:
            data_parts = callback_query.data.split('_')
            if len(data_parts) != 3:
                return
                
            action = data_parts[1]  # 'like' –∏–ª–∏ 'dislike'
            qa_session_id = int(data_parts[2])
            
            rating = 1 if action == 'like' else -1
            success = await save_feedback(qa_session_id, callback_query.from_user.id, rating)
            
            if success:
                emoji = "üëç" if rating == 1 else "üëé"
                await callback_query.answer(f"–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ü–µ–Ω–∫—É! {emoji}")
                
                # –£–±–∏—Ä–∞–µ–º –∫–Ω–æ–ø–∫–∏ –ø–æ—Å–ª–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
                await callback_query.message.edit_reply_markup(reply_markup=None)
            else:
                await callback_query.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ü–µ–Ω–∫–∏", show_alert=True)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∏–¥–±–µ–∫–∞: {e}")
            await callback_query.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞", show_alert=True)

    # –ö–æ–º–∞–Ω–¥–∞ /help
    @dp.message(Command('help'))
    async def help_handler(message: types.Message):
        if message.from_user.id not in AUTHORIZED_USERS:
            await message.answer("‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start.")
            return
        help_text = (
            '<b>–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:</b>\n\n'
            '/start - –Ω–∞—á–∞—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é\n'
            '/status - –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª—å\n'
            '/ask - –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É\n'
            '/cancel - –æ—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é\n'
            "'–ø–æ–≤—Ç–æ—Ä' - –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏\n"
            '/help - –ø–æ–º–æ—â—å'
        )
        if message.from_user.id == ADMIN_CHAT_ID:
            help_text += '\n\n<b>–ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã:</b>\n' \
                        '/train - –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç (.docx) –∏ –æ–±–Ω–æ–≤–∏—Ç—å –ø–æ–∏—Å–∫\n' \
                        '/analytics - –ø–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n' \
                        '/stats - –∫—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–∞–ª–∏–∞—Å –¥–ª—è analytics)\n' \
                        '/compare_search - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π –ø–æ–∏—Å–∫–∞ (A/B —Ç–µ—Å—Ç)'
        await message.answer(help_text, parse_mode='HTML', reply_markup=main_kb)

    # –ö–Ω–æ–ø–∫–∞ ¬´–ü–æ–º–æ—â—å¬ª (—Ä—É—Å—Å–∫–∞—è)
    @dp.message(lambda m: m.text and m.text.strip().lower() == '–ø–æ–º–æ—â—å')
    async def help_button(message: types.Message):
        await help_handler(message)

    # ====== –ê–¥–º–∏–Ω: –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ======
    @dp.message(Command('analytics'))
    async def analytics_handler(message: types.Message):
        if message.from_user.id != ADMIN_CHAT_ID:
            await message.answer('‚ùå –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.')
            return
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
            stats = await get_analytics_stats(days=7)
            popular_questions = await get_popular_questions(limit=5, days=30)
            
            if not stats:
                await message.answer('üìä –ü–æ–∫–∞ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.')
                return
            
            report_lines = [
                'üìä <b>–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –±–æ—Ç–∞ –∑–∞ 7 –¥–Ω–µ–π</b>\n',
                f'üìà <b>–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</b>',
                f'‚Ä¢ –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {stats.get("total_questions", 0)}',
                f'‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {stats.get("avg_response_time_ms", 0)} –º—Å',
                f'‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats.get("avg_confidence", 0)}',
                f'‚Ä¢ –í–æ–ø—Ä–æ—Å–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: {stats.get("questions_with_context", 0)}',
                '',
                f'üë• <b>–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:</b>',
                f'‚Ä¢ –õ–∞–π–∫–æ–≤: {stats.get("likes", 0)} üëç',
                f'‚Ä¢ –î–∏–∑–ª–∞–π–∫–æ–≤: {stats.get("dislikes", 0)} üëé',
                f'‚Ä¢ –£—Ä–æ–≤–µ–Ω—å —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏: {stats.get("satisfaction_rate", 0)}%',
                ''
            ]
            
            # –¢–æ–ø –≤–æ–ø—Ä–æ—Å–æ–≤ –∑–∞ 7 –¥–Ω–µ–π
            if stats.get('top_questions'):
                report_lines.append('üî• <b>–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã (7 –¥–Ω–µ–π):</b>')
                for i, (question, freq) in enumerate(stats['top_questions'][:5], 1):
                    short_q = question[:50] + '...' if len(question) > 50 else question
                    report_lines.append(f'{i}. "{short_q}" ({freq}x)')
                report_lines.append('')
            
            # –ù–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
            if stats.get('unanswered_questions'):
                report_lines.append('‚ùì <b>–ù–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã:</b>')
                for question, freq in stats['unanswered_questions'][:5]:
                    short_q = question[:50] + '...' if len(question) > 50 else question
                    report_lines.append(f'‚Ä¢ "{short_q}" ({freq}x)')
                report_lines.append('')
            
            # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∑–∞ –º–µ—Å—è—Ü
            if popular_questions:
                report_lines.append('üìÖ <b>–¢–æ–ø –≤–æ–ø—Ä–æ—Å–æ–≤ –∑–∞ –º–µ—Å—è—Ü:</b>')
                for i, (question, freq, avg_conf) in enumerate(popular_questions[:3], 1):
                    short_q = question[:40] + '...' if len(question) > 40 else question
                    conf_str = f'(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {round(avg_conf or 0, 2)})' if avg_conf else ''
                    report_lines.append(f'{i}. "{short_q}" ({freq}x) {conf_str}')
            
            report_text = '\n'.join(report_lines)
            await message.answer(report_text, parse_mode='HTML')
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
            await message.answer('‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏.')

    @dp.message(Command('stats'))
    async def stats_handler(message: types.Message):
        """–ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–∞–ª–∏–∞—Å –¥–ª—è analytics)"""
        if message.from_user.id != ADMIN_CHAT_ID:
            await message.answer('‚ùå –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.')
            return
        await analytics_handler(message)

    # ====== –ê–¥–º–∏–Ω: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π –ø–æ–∏—Å–∫–∞ ======
    @dp.message(Command('compare_search'))
    async def compare_search_handler(message: types.Message):
        if message.from_user.id != ADMIN_CHAT_ID:
            await message.answer('‚ùå –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.')
            return
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
            import aiosqlite
            async with aiosqlite.connect('employees.db') as db:
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ v1 (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ [v2])
                async with db.execute(
                    """SELECT 
                        COUNT(*) as total,
                        AVG(response_time_ms) as avg_time,
                        AVG(confidence_score) as avg_confidence
                    FROM qa_sessions 
                    WHERE created_at >= datetime('now', '-7 days')
                    AND (answer NOT LIKE '[v2]%' OR answer IS NULL)"""
                ) as cursor:
                    v1_stats = await cursor.fetchone()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ v2 (—Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º [v2])
                async with db.execute(
                    """SELECT 
                        COUNT(*) as total,
                        AVG(response_time_ms) as avg_time,
                        AVG(confidence_score) as avg_confidence
                    FROM qa_sessions 
                    WHERE created_at >= datetime('now', '-7 days')
                    AND answer LIKE '[v2]%'"""
                ) as cursor:
                    v2_stats = await cursor.fetchone()
                
                # –§–∏–¥–±–µ–∫ –ø–æ –≤–µ—Ä—Å–∏—è–º
                async with db.execute(
                    """SELECT 
                        CASE WHEN qa.answer LIKE '[v2]%' THEN 'v2' ELSE 'v1' END as version,
                        SUM(CASE WHEN f.rating = 1 THEN 1 ELSE 0 END) as likes,
                        SUM(CASE WHEN f.rating = -1 THEN 1 ELSE 0 END) as dislikes
                    FROM feedback f
                    JOIN qa_sessions qa ON f.qa_session_id = qa.id
                    WHERE qa.created_at >= datetime('now', '-7 days')
                    GROUP BY version"""
                ) as cursor:
                    feedback_stats = await cursor.fetchall()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
            report_lines = [
                'üîç <b>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π –ø–æ–∏—Å–∫–∞ (7 –¥–Ω–µ–π)</b>\n',
                f'üìä <b>–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:</b>',
                f'‚Ä¢ USE_SEARCH_V2: {USE_SEARCH_V2}',
                f'‚Ä¢ SEARCH_V2_PERCENTAGE: {SEARCH_V2_PERCENTAGE}%',
                '',
                f'üîß <b>–ü–æ–∏—Å–∫ V1 (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π):</b>',
                f'‚Ä¢ –ó–∞–ø—Ä–æ—Å–æ–≤: {v1_stats[0] if v1_stats else 0}',
                f'‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {round(v1_stats[1] or 0)} –º—Å',
                f'‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {round(v1_stats[2] or 0, 3)}',
                '',
                f'‚ö° <b>–ü–æ–∏—Å–∫ V2 (Cross-Encoder):</b>',
                f'‚Ä¢ –ó–∞–ø—Ä–æ—Å–æ–≤: {v2_stats[0] if v2_stats else 0}',
                f'‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {round(v2_stats[1] or 0)} –º—Å',
                f'‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {round(v2_stats[2] or 0, 3)}',
                ''
            ]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∏–¥–±–µ–∫–∞
            if feedback_stats:
                report_lines.append('üë• <b>–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:</b>')
                for version, likes, dislikes in feedback_stats:
                    total = likes + dislikes
                    satisfaction = round(likes / total * 100, 1) if total > 0 else 0
                    report_lines.append(f'‚Ä¢ {version.upper()}: {satisfaction}% ({likes}üëç / {dislikes}üëé)')
                report_lines.append('')
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if v2_stats and v1_stats and v2_stats[0] > 0 and v1_stats[0] > 0:
                v2_faster = (v2_stats[1] or 0) < (v1_stats[1] or 0)
                v2_more_confident = (v2_stats[2] or 0) > (v1_stats[2] or 0)
                
                report_lines.append('üí° <b>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</b>')
                if v2_faster and v2_more_confident:
                    report_lines.append('‚úÖ V2 –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç V1 - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å SEARCH_V2_PERCENTAGE')
                elif v2_more_confident:
                    report_lines.append('‚úÖ V2 —Ç–æ—á–Ω–µ–µ, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ - –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ–ª—é –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ')
                else:
                    report_lines.append('‚ö†Ô∏è V1 –ø–æ–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã')
            
            await message.answer('\n'.join(report_lines), parse_mode='HTML')
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –≤–µ—Ä—Å–∏–π –ø–æ–∏—Å–∫–∞: {e}")
            await message.answer('‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.')

        if message.from_user.id == ADMIN_CHAT_ID:
            help_text += '\n\n<b>–ê–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã:</b>\n' \
                        '/train - –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç (.docx) –∏ –æ–±–Ω–æ–≤–∏—Ç—å –ø–æ–∏—Å–∫\n' \
                        '/analytics - –ø–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n' \
                        '/stats - –∫—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–∞–ª–∏–∞—Å –¥–ª—è analytics)\n' \
                        '/compare_search - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π –ø–æ–∏—Å–∫–∞ (A/B —Ç–µ—Å—Ç)'